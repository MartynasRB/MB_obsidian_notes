---
journal: research-notes
journal-start-date: 2025-01-09
journal-end-date: 2025-01-09
journal-section: day
---
The SBAS tutorial for using ASF data with MintPy will be carried out today to check if everything works correctly.
1. Choose L1 Single Look Complex data on SLC.
2. Choose a starting date and image, and press SBAS (SBAS search)
3. On the right, we can see an SBAS connection view, and we can adjust our thresholds for perpendicular and temporal baselines. On the left, we can see the pair count for the time period. **We need to decide on appropriate temporal and perpendicular baselines!**
4. Above the timeline, we can add custom pairs (for example, to avoid clusters).
5. After setting the appropriate pairs in the timeline, we can press the On Demand add button and choose to add InSAR GAMMA SLC pairs.![[Pasted image 20250109103317.png]] ![[Pasted image 20250109103348.png]]
6. Go to the OnDemand queue and press *Set MintPy options*. This adds a look vector layer and attaches a DEM file too. Below the settings, we can see the full list of demanded InSAR pairs.
7. Press Submit at the bottom, name the submission and confirm.
8. Login to opensarlab.asf.alaska.edu, where MintPy workflows are held to be used with ASF Vertex data.

**MintPy Local VSCODE Path:**
1. In a new VSCode folder, use a Conda environment by creating it locally - the environment's name is *thesis*:
```
conda create -n thesis python=3.11.9
```
2. In the OnDemand queue, once products are processed, download the Python script to download data.
3. Put the Python script in the folder where the files are to be downloaded, and run it.
4. After download, install MintPy & dependencies:
```
	conda install -c conda-forge mintpy
```
5. Set dask distributed processing temporary directory as a config setting (I set it as a .yaml file in ~/etc/dask, but it can also be set using `dask.config.set({'temporary-directory':'/tmp'})`
6. Add additional environmental variables by creating a .env file inside the workspace.

Before experimenting with my own data, time to run some built-in tutorials.

1. Tutorial using Fernandina Volcano seems successsful, everything worked and produced the expected results.

For tomorrow, we need to follow the full tutorial on running MintPy using Hyp3 SBAS data. Follow this: [GitHub - ASFOpenSARlab/opensarlab\_MintPy\_Recipe\_Book: A Jupyter-Book containing data recipes for creating HyP3 Sentinel-1 IINSAR\_GAMMA and INSAR\_ISCE\_BURST Small Baseline Subset (SBAS) Time Series Analyses with MintPy](https://github.com/ASFOpenSARlab/opensarlab_MintPy_Recipe_Book?tab=readme-ov-file)

Also, JupyterLab is now also installed, might be a bit easier to work with.

